{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All'inizio del notebook\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Aggiungi il root del progetto al Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from wavelet_lib.datasets import TileDataset\n",
    "from wavelet_lib.models import TileWaveletClassifier\n",
    "from torch.utils.data import Subset\n",
    "from wavelet_lib.processors import DroneImageWaveletProcessor\n",
    "from wavelet_lib.base import BaseWaveletDataset, WaveletProcessor\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione\n",
    "SCATTERING_PARAMS = {\n",
    "    \"J\": 2,\n",
    "    \"shape\": (32, 32),\n",
    "    \"max_order\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trasformazioni\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor initialized with shape (32, 32)\n",
      "\n",
      "Creating dataset...\n",
      "\n",
      "Loading raw data...\n",
      "Raw data loading completed!\n",
      "\n",
      "Preparing wavelet representations...\n",
      "Wavelet representations completed!\n",
      "\n",
      "Loading raw data...\n",
      "Loading file 100/39690 (0.3%)\n",
      "Loading file 200/39690 (0.5%)\n",
      "Loading file 300/39690 (0.8%)\n",
      "Loading file 400/39690 (1.0%)\n",
      "Loading file 500/39690 (1.3%)\n",
      "Loading file 600/39690 (1.5%)\n",
      "Loading file 700/39690 (1.8%)\n",
      "Loading file 800/39690 (2.0%)\n",
      "Loading file 900/39690 (2.3%)\n",
      "Loading file 1000/39690 (2.5%)\n",
      "Loading file 1100/39690 (2.8%)\n",
      "Loading file 1200/39690 (3.0%)\n",
      "Loading file 1300/39690 (3.3%)\n",
      "Loading file 1400/39690 (3.5%)\n",
      "Loading file 1500/39690 (3.8%)\n",
      "Loading file 1600/39690 (4.0%)\n",
      "Loading file 1700/39690 (4.3%)\n",
      "Loading file 1800/39690 (4.5%)\n",
      "Loading file 1900/39690 (4.8%)\n",
      "Loading file 2000/39690 (5.0%)\n",
      "Loading file 2100/39690 (5.3%)\n",
      "Loading file 2200/39690 (5.5%)\n",
      "Loading file 2300/39690 (5.8%)\n",
      "Loading file 2400/39690 (6.0%)\n",
      "Loading file 2500/39690 (6.3%)\n",
      "Loading file 2600/39690 (6.6%)\n",
      "Loading file 2700/39690 (6.8%)\n",
      "Loading file 2800/39690 (7.1%)\n",
      "Loading file 2900/39690 (7.3%)\n",
      "Loading file 3000/39690 (7.6%)\n",
      "Loading file 3100/39690 (7.8%)\n",
      "Loading file 3200/39690 (8.1%)\n",
      "Loading file 3300/39690 (8.3%)\n",
      "Loading file 3400/39690 (8.6%)\n",
      "Loading file 3500/39690 (8.8%)\n",
      "Loading file 3600/39690 (9.1%)\n",
      "Loading file 3700/39690 (9.3%)\n",
      "Loading file 3800/39690 (9.6%)\n",
      "Loading file 3900/39690 (9.8%)\n",
      "Loading file 4000/39690 (10.1%)\n",
      "Loading file 4100/39690 (10.3%)\n",
      "Loading file 4200/39690 (10.6%)\n",
      "Loading file 4300/39690 (10.8%)\n",
      "Loading file 4400/39690 (11.1%)\n",
      "Loading file 4500/39690 (11.3%)\n",
      "Loading file 4600/39690 (11.6%)\n",
      "Loading file 4700/39690 (11.8%)\n",
      "Loading file 4800/39690 (12.1%)\n",
      "Loading file 4900/39690 (12.3%)\n",
      "Loading file 5000/39690 (12.6%)\n",
      "Loading file 5100/39690 (12.8%)\n",
      "Loading file 5200/39690 (13.1%)\n",
      "Loading file 5300/39690 (13.4%)\n",
      "Loading file 5400/39690 (13.6%)\n",
      "Loading file 5500/39690 (13.9%)\n",
      "Loading file 5600/39690 (14.1%)\n",
      "Loading file 5700/39690 (14.4%)\n",
      "Loading file 5800/39690 (14.6%)\n",
      "Loading file 5900/39690 (14.9%)\n",
      "Loading file 6000/39690 (15.1%)\n",
      "Loading file 6100/39690 (15.4%)\n",
      "Loading file 6200/39690 (15.6%)\n",
      "Loading file 6300/39690 (15.9%)\n",
      "Loading file 6400/39690 (16.1%)\n",
      "Loading file 6500/39690 (16.4%)\n",
      "Loading file 6600/39690 (16.6%)\n",
      "Loading file 6700/39690 (16.9%)\n",
      "Loading file 6800/39690 (17.1%)\n",
      "Loading file 6900/39690 (17.4%)\n",
      "Loading file 7000/39690 (17.6%)\n",
      "Loading file 7100/39690 (17.9%)\n",
      "Loading file 7200/39690 (18.1%)\n",
      "Loading file 7300/39690 (18.4%)\n",
      "Loading file 7400/39690 (18.6%)\n",
      "Loading file 7500/39690 (18.9%)\n",
      "Loading file 7600/39690 (19.1%)\n",
      "Loading file 7700/39690 (19.4%)\n",
      "Loading file 7800/39690 (19.7%)\n",
      "Loading file 7900/39690 (19.9%)\n",
      "Loading file 8000/39690 (20.2%)\n",
      "Loading file 8100/39690 (20.4%)\n",
      "Loading file 8200/39690 (20.7%)\n",
      "Loading file 8300/39690 (20.9%)\n",
      "Loading file 8400/39690 (21.2%)\n",
      "Loading file 8500/39690 (21.4%)\n",
      "Loading file 8600/39690 (21.7%)\n",
      "Loading file 8700/39690 (21.9%)\n",
      "Loading file 8800/39690 (22.2%)\n",
      "Loading file 8900/39690 (22.4%)\n",
      "Loading file 9000/39690 (22.7%)\n",
      "Loading file 9100/39690 (22.9%)\n",
      "Loading file 9200/39690 (23.2%)\n",
      "Loading file 9300/39690 (23.4%)\n",
      "Loading file 9400/39690 (23.7%)\n",
      "Loading file 9500/39690 (23.9%)\n",
      "Loading file 9600/39690 (24.2%)\n",
      "Loading file 9700/39690 (24.4%)\n",
      "Loading file 9800/39690 (24.7%)\n",
      "Loading file 9900/39690 (24.9%)\n",
      "Loading file 10000/39690 (25.2%)\n",
      "Loading file 10100/39690 (25.4%)\n",
      "Loading file 10200/39690 (25.7%)\n",
      "Loading file 10300/39690 (26.0%)\n",
      "Loading file 10400/39690 (26.2%)\n",
      "Loading file 10500/39690 (26.5%)\n",
      "Loading file 10600/39690 (26.7%)\n",
      "Loading file 10700/39690 (27.0%)\n",
      "Loading file 10800/39690 (27.2%)\n",
      "Loading file 10900/39690 (27.5%)\n",
      "Loading file 11000/39690 (27.7%)\n",
      "Loading file 11100/39690 (28.0%)\n",
      "Loading file 11200/39690 (28.2%)\n",
      "Loading file 11300/39690 (28.5%)\n",
      "Loading file 11400/39690 (28.7%)\n",
      "Loading file 11500/39690 (29.0%)\n",
      "Loading file 11600/39690 (29.2%)\n",
      "Loading file 11700/39690 (29.5%)\n",
      "Loading file 11800/39690 (29.7%)\n",
      "Loading file 11900/39690 (30.0%)\n",
      "Loading file 12000/39690 (30.2%)\n",
      "Loading file 12100/39690 (30.5%)\n",
      "Loading file 12200/39690 (30.7%)\n",
      "Loading file 12300/39690 (31.0%)\n",
      "Loading file 12400/39690 (31.2%)\n",
      "Loading file 12500/39690 (31.5%)\n",
      "Loading file 12600/39690 (31.7%)\n",
      "Loading file 12700/39690 (32.0%)\n",
      "Loading file 12800/39690 (32.2%)\n",
      "Loading file 12900/39690 (32.5%)\n",
      "Loading file 13000/39690 (32.8%)\n",
      "Loading file 13100/39690 (33.0%)\n",
      "Loading file 13200/39690 (33.3%)\n",
      "Loading file 13300/39690 (33.5%)\n",
      "Loading file 13400/39690 (33.8%)\n",
      "Loading file 13500/39690 (34.0%)\n",
      "Loading file 13600/39690 (34.3%)\n",
      "Loading file 13700/39690 (34.5%)\n",
      "Loading file 13800/39690 (34.8%)\n",
      "Loading file 13900/39690 (35.0%)\n",
      "Loading file 14000/39690 (35.3%)\n",
      "Loading file 14100/39690 (35.5%)\n",
      "Loading file 14200/39690 (35.8%)\n",
      "Loading file 14300/39690 (36.0%)\n",
      "Loading file 14400/39690 (36.3%)\n",
      "Loading file 14500/39690 (36.5%)\n",
      "Loading file 14600/39690 (36.8%)\n",
      "Loading file 14700/39690 (37.0%)\n",
      "Loading file 14800/39690 (37.3%)\n",
      "Loading file 14900/39690 (37.5%)\n",
      "Loading file 15000/39690 (37.8%)\n",
      "Loading file 15100/39690 (38.0%)\n",
      "Loading file 15200/39690 (38.3%)\n",
      "Loading file 15300/39690 (38.5%)\n",
      "Loading file 15400/39690 (38.8%)\n",
      "Loading file 15500/39690 (39.1%)\n",
      "Loading file 15600/39690 (39.3%)\n",
      "Loading file 15700/39690 (39.6%)\n",
      "Loading file 15800/39690 (39.8%)\n",
      "Loading file 15900/39690 (40.1%)\n",
      "Loading file 16000/39690 (40.3%)\n",
      "Loading file 16100/39690 (40.6%)\n",
      "Loading file 16200/39690 (40.8%)\n",
      "Loading file 16300/39690 (41.1%)\n",
      "Loading file 16400/39690 (41.3%)\n",
      "Loading file 16500/39690 (41.6%)\n",
      "Loading file 16600/39690 (41.8%)\n",
      "Loading file 16700/39690 (42.1%)\n",
      "Loading file 16800/39690 (42.3%)\n",
      "Loading file 16900/39690 (42.6%)\n",
      "Loading file 17000/39690 (42.8%)\n",
      "Loading file 17100/39690 (43.1%)\n",
      "Loading file 17200/39690 (43.3%)\n",
      "Loading file 17300/39690 (43.6%)\n",
      "Loading file 17400/39690 (43.8%)\n",
      "Loading file 17500/39690 (44.1%)\n",
      "Loading file 17600/39690 (44.3%)\n",
      "Loading file 17700/39690 (44.6%)\n",
      "Loading file 17800/39690 (44.8%)\n",
      "Loading file 17900/39690 (45.1%)\n",
      "Loading file 18000/39690 (45.4%)\n",
      "Loading file 18100/39690 (45.6%)\n",
      "Loading file 18200/39690 (45.9%)\n",
      "Loading file 18300/39690 (46.1%)\n",
      "Loading file 18400/39690 (46.4%)\n",
      "Loading file 18500/39690 (46.6%)\n",
      "Loading file 18600/39690 (46.9%)\n",
      "Loading file 18700/39690 (47.1%)\n",
      "Loading file 18800/39690 (47.4%)\n",
      "Loading file 18900/39690 (47.6%)\n",
      "Loading file 19000/39690 (47.9%)\n",
      "Loading file 19100/39690 (48.1%)\n",
      "Loading file 19200/39690 (48.4%)\n",
      "Loading file 19300/39690 (48.6%)\n",
      "Loading file 19400/39690 (48.9%)\n",
      "Loading file 19500/39690 (49.1%)\n",
      "Loading file 19600/39690 (49.4%)\n",
      "Loading file 19700/39690 (49.6%)\n",
      "Loading file 19800/39690 (49.9%)\n",
      "Loading file 19900/39690 (50.1%)\n",
      "Loading file 20000/39690 (50.4%)\n",
      "Loading file 20100/39690 (50.6%)\n",
      "Loading file 20200/39690 (50.9%)\n",
      "Loading file 20300/39690 (51.1%)\n",
      "Loading file 20400/39690 (51.4%)\n",
      "Loading file 20500/39690 (51.7%)\n",
      "Loading file 20600/39690 (51.9%)\n",
      "Loading file 20700/39690 (52.2%)\n",
      "Loading file 20800/39690 (52.4%)\n",
      "Loading file 20900/39690 (52.7%)\n",
      "Loading file 21000/39690 (52.9%)\n",
      "Loading file 21100/39690 (53.2%)\n",
      "Loading file 21200/39690 (53.4%)\n",
      "Loading file 21300/39690 (53.7%)\n",
      "Loading file 21400/39690 (53.9%)\n",
      "Loading file 21500/39690 (54.2%)\n",
      "Loading file 21600/39690 (54.4%)\n",
      "Loading file 21700/39690 (54.7%)\n",
      "Loading file 21800/39690 (54.9%)\n",
      "Loading file 21900/39690 (55.2%)\n",
      "Loading file 22000/39690 (55.4%)\n",
      "Loading file 22100/39690 (55.7%)\n",
      "Loading file 22200/39690 (55.9%)\n",
      "Loading file 22300/39690 (56.2%)\n",
      "Loading file 22400/39690 (56.4%)\n",
      "Loading file 22500/39690 (56.7%)\n",
      "Loading file 22600/39690 (56.9%)\n",
      "Loading file 22700/39690 (57.2%)\n",
      "Loading file 22800/39690 (57.4%)\n",
      "Loading file 22900/39690 (57.7%)\n",
      "Loading file 23000/39690 (57.9%)\n",
      "Loading file 23100/39690 (58.2%)\n",
      "Loading file 23200/39690 (58.5%)\n",
      "Loading file 23300/39690 (58.7%)\n",
      "Loading file 23400/39690 (59.0%)\n",
      "Loading file 23500/39690 (59.2%)\n",
      "Loading file 23600/39690 (59.5%)\n",
      "Loading file 23700/39690 (59.7%)\n",
      "Loading file 23800/39690 (60.0%)\n",
      "Loading file 23900/39690 (60.2%)\n",
      "Loading file 24000/39690 (60.5%)\n",
      "Loading file 24100/39690 (60.7%)\n",
      "Loading file 24200/39690 (61.0%)\n",
      "Loading file 24300/39690 (61.2%)\n",
      "Loading file 24400/39690 (61.5%)\n",
      "Loading file 24500/39690 (61.7%)\n",
      "Loading file 24600/39690 (62.0%)\n",
      "Loading file 24700/39690 (62.2%)\n",
      "Loading file 24800/39690 (62.5%)\n",
      "Loading file 24900/39690 (62.7%)\n",
      "Loading file 25000/39690 (63.0%)\n",
      "Loading file 25100/39690 (63.2%)\n",
      "Loading file 25200/39690 (63.5%)\n",
      "Loading file 25300/39690 (63.7%)\n",
      "Loading file 25400/39690 (64.0%)\n",
      "Loading file 25500/39690 (64.2%)\n",
      "Loading file 25600/39690 (64.5%)\n",
      "Loading file 25700/39690 (64.8%)\n",
      "Loading file 25800/39690 (65.0%)\n",
      "Loading file 25900/39690 (65.3%)\n",
      "Loading file 26000/39690 (65.5%)\n",
      "Loading file 26100/39690 (65.8%)\n",
      "Loading file 26200/39690 (66.0%)\n",
      "Loading file 26300/39690 (66.3%)\n",
      "Loading file 26400/39690 (66.5%)\n",
      "Loading file 26500/39690 (66.8%)\n",
      "Loading file 26600/39690 (67.0%)\n",
      "Loading file 26700/39690 (67.3%)\n",
      "Loading file 26800/39690 (67.5%)\n",
      "Loading file 26900/39690 (67.8%)\n",
      "Loading file 27000/39690 (68.0%)\n",
      "Loading file 27100/39690 (68.3%)\n",
      "Loading file 27200/39690 (68.5%)\n",
      "Loading file 27300/39690 (68.8%)\n",
      "Loading file 27400/39690 (69.0%)\n",
      "Loading file 27500/39690 (69.3%)\n",
      "Loading file 27600/39690 (69.5%)\n",
      "Loading file 27700/39690 (69.8%)\n",
      "Loading file 27800/39690 (70.0%)\n",
      "Loading file 27900/39690 (70.3%)\n",
      "Loading file 28000/39690 (70.5%)\n",
      "Loading file 28100/39690 (70.8%)\n",
      "Loading file 28200/39690 (71.1%)\n",
      "Loading file 28300/39690 (71.3%)\n",
      "Loading file 28400/39690 (71.6%)\n",
      "Loading file 28500/39690 (71.8%)\n",
      "Loading file 28600/39690 (72.1%)\n",
      "Loading file 28700/39690 (72.3%)\n",
      "Loading file 28800/39690 (72.6%)\n",
      "Loading file 28900/39690 (72.8%)\n",
      "Loading file 29000/39690 (73.1%)\n",
      "Loading file 29100/39690 (73.3%)\n",
      "Loading file 29200/39690 (73.6%)\n",
      "Loading file 29300/39690 (73.8%)\n",
      "Loading file 29400/39690 (74.1%)\n",
      "Loading file 29500/39690 (74.3%)\n",
      "Loading file 29600/39690 (74.6%)\n",
      "Loading file 29700/39690 (74.8%)\n",
      "Loading file 29800/39690 (75.1%)\n",
      "Loading file 29900/39690 (75.3%)\n",
      "Loading file 30000/39690 (75.6%)\n",
      "Loading file 30100/39690 (75.8%)\n",
      "Loading file 30200/39690 (76.1%)\n",
      "Loading file 30300/39690 (76.3%)\n",
      "Loading file 30400/39690 (76.6%)\n",
      "Loading file 30500/39690 (76.8%)\n",
      "Loading file 30600/39690 (77.1%)\n",
      "Loading file 30700/39690 (77.3%)\n",
      "Loading file 30800/39690 (77.6%)\n",
      "Loading file 30900/39690 (77.9%)\n",
      "Loading file 31000/39690 (78.1%)\n",
      "Loading file 31100/39690 (78.4%)\n",
      "Loading file 31200/39690 (78.6%)\n",
      "Loading file 31300/39690 (78.9%)\n",
      "Loading file 31400/39690 (79.1%)\n",
      "Loading file 31500/39690 (79.4%)\n",
      "Loading file 31600/39690 (79.6%)\n",
      "Loading file 31700/39690 (79.9%)\n",
      "Loading file 31800/39690 (80.1%)\n",
      "Loading file 31900/39690 (80.4%)\n",
      "Loading file 32000/39690 (80.6%)\n",
      "Loading file 32100/39690 (80.9%)\n",
      "Loading file 32200/39690 (81.1%)\n",
      "Loading file 32300/39690 (81.4%)\n",
      "Loading file 32400/39690 (81.6%)\n",
      "Loading file 32500/39690 (81.9%)\n",
      "Loading file 32600/39690 (82.1%)\n",
      "Loading file 32700/39690 (82.4%)\n",
      "Loading file 32800/39690 (82.6%)\n",
      "Loading file 32900/39690 (82.9%)\n",
      "Loading file 33000/39690 (83.1%)\n",
      "Loading file 33100/39690 (83.4%)\n",
      "Loading file 33200/39690 (83.6%)\n",
      "Loading file 33300/39690 (83.9%)\n",
      "Loading file 33400/39690 (84.2%)\n",
      "Loading file 33500/39690 (84.4%)\n",
      "Loading file 33600/39690 (84.7%)\n",
      "Loading file 33700/39690 (84.9%)\n",
      "Loading file 33800/39690 (85.2%)\n",
      "Loading file 33900/39690 (85.4%)\n",
      "Loading file 34000/39690 (85.7%)\n",
      "Loading file 34100/39690 (85.9%)\n",
      "Loading file 34200/39690 (86.2%)\n",
      "Loading file 34300/39690 (86.4%)\n",
      "Loading file 34400/39690 (86.7%)\n",
      "Loading file 34500/39690 (86.9%)\n",
      "Loading file 34600/39690 (87.2%)\n",
      "Loading file 34700/39690 (87.4%)\n",
      "Loading file 34800/39690 (87.7%)\n",
      "Loading file 34900/39690 (87.9%)\n",
      "Loading file 35000/39690 (88.2%)\n",
      "Loading file 35100/39690 (88.4%)\n",
      "Loading file 35200/39690 (88.7%)\n",
      "Loading file 35300/39690 (88.9%)\n",
      "Loading file 35400/39690 (89.2%)\n",
      "Loading file 35500/39690 (89.4%)\n",
      "Loading file 35600/39690 (89.7%)\n",
      "Loading file 35700/39690 (89.9%)\n",
      "Loading file 35800/39690 (90.2%)\n",
      "Loading file 35900/39690 (90.5%)\n",
      "Loading file 36000/39690 (90.7%)\n",
      "Loading file 36100/39690 (91.0%)\n",
      "Loading file 36200/39690 (91.2%)\n",
      "Loading file 36300/39690 (91.5%)\n",
      "Loading file 36400/39690 (91.7%)\n",
      "Loading file 36500/39690 (92.0%)\n",
      "Loading file 36600/39690 (92.2%)\n",
      "Loading file 36700/39690 (92.5%)\n",
      "Loading file 36800/39690 (92.7%)\n",
      "Loading file 36900/39690 (93.0%)\n",
      "Loading file 37000/39690 (93.2%)\n",
      "Loading file 37100/39690 (93.5%)\n",
      "Loading file 37200/39690 (93.7%)\n",
      "Loading file 37300/39690 (94.0%)\n",
      "Loading file 37400/39690 (94.2%)\n",
      "Loading file 37500/39690 (94.5%)\n",
      "Loading file 37600/39690 (94.7%)\n",
      "Loading file 37700/39690 (95.0%)\n",
      "Loading file 37800/39690 (95.2%)\n",
      "Loading file 37900/39690 (95.5%)\n",
      "Loading file 38000/39690 (95.7%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCreating dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Dataset e DataLoader\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTileDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/brus/Projects/wavelet/datasets/HPL_images/custom_dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbalance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDataset creation completed:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/wavelet/wavelet_lib/datasets.py:17\u001b[0m, in \u001b[0;36mTileDataset.__init__\u001b[0;34m(self, dataset_root, processor, transform, balance, allowed_extensions)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     10\u001b[0m     root\u001b[38;5;241m=\u001b[39mdataset_root,\n\u001b[1;32m     11\u001b[0m     processor\u001b[38;5;241m=\u001b[39mprocessor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     allowed_extensions\u001b[38;5;241m=\u001b[39mallowed_extensions\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Initialize after parent class initialization\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwavelet_representations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_wavelet_representation()\n",
      "File \u001b[0;32m~/Projects/wavelet/wavelet_lib/datasets.py:52\u001b[0m, in \u001b[0;36mTileDataset.load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# Stampa progresso ogni 100 file\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(idx\u001b[38;5;241m/\u001b[39mtotal_files)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     54\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "File \u001b[0;32m~/Projects/wavelet/wavelet_venv/lib/python3.12/site-packages/PIL/Image.py:3476\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3473\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m   3474\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 3476\u001b[0m prefix \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3478\u001b[0m preinit()\n\u001b[1;32m   3480\u001b[0m warning_messages: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "processor = DroneImageWaveletProcessor(J=2, shape=(32, 32))\n",
    "print(f\"Processor initialized with shape {processor.shape}\")\n",
    "\n",
    "print(\"\\nCreating dataset...\")\n",
    "\n",
    "# Dataset e DataLoader\n",
    "dataset = TileDataset(\n",
    "    dataset_root=\"/home/brus/Projects/wavelet/datasets/HPL_images/custom_dataset\",\n",
    "    processor=processor,\n",
    "    transform=transform,\n",
    "    balance=True,\n",
    "    allowed_extensions={'.jpg'}\n",
    ")\n",
    "first_data, _ = dataset[0]\n",
    "print(f\"First item shape: {first_data.shape}\")\n",
    "\n",
    "print(f\"\\nDataset creation completed:\")\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "print(f\"Number of classes: {len(dataset.classes)}\")\n",
    "print(f\"Classes: {dataset.classes}\")\n",
    "\n",
    "# Salvataggio del dataset elaborato\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Crea la directory per i dataset elaborati se non esiste\n",
    "save_dir = \"/home/brus/Projects/wavelet/datasets/wavelet_datasets\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Nome del file di salvataggio\n",
    "save_path = os.path.join(save_dir, \"processed_tile_dataset.pkl\")\n",
    "\n",
    "# Salva il dataset\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'data': dataset.data,\n",
    "        'wavelet_representations': dataset.wavelet_representations,\n",
    "        'samples': dataset.samples,\n",
    "        'classes': dataset.classes,\n",
    "        'class_to_idx': dataset.class_to_idx\n",
    "    }, f)\n",
    "\n",
    "print(f\"\\nDataset salvato in: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dataset da /home/brus/Projects/wavelet/datasets/processed_datasets/processed_tile_dataset.pkl\n",
      "\n",
      "Informazioni Dataset:\n",
      "Numero totale campioni: 39690\n",
      "Numero classi: 7\n",
      "Classi disponibili: ['human structure', 'mudflat', 'street', 'vegetation 1', 'vegetation 2', 'vegetation 3', 'water']\n"
     ]
    }
   ],
   "source": [
    "# carica dataset da pickle\n",
    "\n",
    "class LoadedTileDataset(Dataset):\n",
    "    def __init__(self, pickle_path):\n",
    "        # Carica il dataset salvato\n",
    "        print(f\"Caricamento dataset da {pickle_path}\")\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            saved_data = pickle.load(f)\n",
    "            \n",
    "        # Estrai i componenti\n",
    "        self.data = saved_data['data']\n",
    "        self.wavelet_representations = saved_data['wavelet_representations']\n",
    "        self.samples = saved_data['samples']\n",
    "        self.classes = saved_data['classes']\n",
    "        self.class_to_idx = saved_data['class_to_idx']\n",
    "        \n",
    "        print(\"\\nInformazioni Dataset:\")\n",
    "        print(f\"Numero totale campioni: {len(self.samples)}\")\n",
    "        print(f\"Numero classi: {len(self.classes)}\")\n",
    "        print(f\"Classi disponibili: {self.classes}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filepath, label = self.samples[idx]\n",
    "        # Usa la rappresentazione wavelet pre-calcolata\n",
    "        image = self.wavelet_representations[filepath]\n",
    "        return image, label\n",
    "\n",
    "# Carica il dataset\n",
    "pickle_path = \"/home/brus/Projects/wavelet/datasets/processed_datasets/processed_tile_dataset.pkl\"\n",
    "dataset = LoadedTileDataset(pickle_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(dataset)), \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=[label for _, label in dataset.samples]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TileWaveletClassifier(\n",
    "    scattering_params=SCATTERING_PARAMS\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                              RIEPILOGO CONFIGURAZIONE                              \n",
      "================================================================================\n",
      "\n",
      "[1] DATASET:\n",
      "  • Numero di classi: 7\n",
      "  • Classi: ['human structure', 'mudflat', 'street', 'vegetation 1', 'vegetation 2', 'vegetation 3', 'water']\n",
      "  • Campioni totali: 39690\n",
      "  • Split: 31752 training / 7938 test\n",
      "\n",
      "[2] RAPPRESENTAZIONI WAVELET:\n",
      "  • Shape rappresentazione: torch.Size([3, 81, 8, 8])\n",
      "  • Tipo dati: torch.float32\n",
      "  • Numero totale rappresentazioni: 39690\n",
      "\n",
      "[3] MODELLO:\n",
      "  • Architettura: TileWaveletClassifier\n",
      "  • Parametri totali: 21,282,317\n",
      "  • Parametri allenabili: 21,282,317\n",
      "  • Device: cuda:0\n",
      "\n",
      "[4] DATALOADER:\n",
      "  • Batch size training: 128\n",
      "  • Batch size test: 128\n",
      "  • Training batches: 249\n",
      "  • Test batches: 63\n",
      "  • Num workers: 4\n",
      "\n",
      "[5] SISTEMA:\n",
      "  • PyTorch version: 2.6.0+cu124\n",
      "  • CUDA disponibile: True\n",
      "  • Dispositivo CUDA: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "  • Memoria totale GPU: 3.97 GB\n",
      "  • Memoria allocata GPU: 0.09 GB\n",
      "  • CPU count: 16\n",
      "\n",
      "================================================================================\n",
      "                         CONFIGURAZIONE PRONTA PER L'ADDESTRAMENTO                         \n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_configuration_summary(dataset, train_loader, test_loader, model):\n",
    "    \"\"\"\n",
    "    Stampa un riepilogo dettagliato della configurazione del sistema.\n",
    "    \"\"\"    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" \"*30 + \"RIEPILOGO CONFIGURAZIONE\" + \" \"*30)\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Informazioni sul dataset\n",
    "    print(\"\\n[1] DATASET:\")\n",
    "    print(f\"  • Numero di classi: {len(dataset.classes)}\")\n",
    "    print(f\"  • Classi: {dataset.classes}\")\n",
    "    print(f\"  • Campioni totali: {len(dataset)}\")\n",
    "    print(f\"  • Split: {len(train_loader.dataset)} training / {len(test_loader.dataset)} test\")\n",
    "    \n",
    "    # Informazioni sulle rappresentazioni wavelet\n",
    "    print(\"\\n[2] RAPPRESENTAZIONI WAVELET:\")\n",
    "    sample_key = list(dataset.wavelet_representations.keys())[0]\n",
    "    sample_repr = dataset.wavelet_representations[sample_key]\n",
    "    print(f\"  • Shape rappresentazione: {sample_repr.shape}\")\n",
    "    print(f\"  • Tipo dati: {sample_repr.dtype}\")\n",
    "    print(f\"  • Numero totale rappresentazioni: {len(dataset.wavelet_representations)}\")\n",
    "    \n",
    "    # Informazioni sul modello\n",
    "    print(\"\\n[3] MODELLO:\")\n",
    "    print(f\"  • Architettura: {model.__class__.__name__}\")\n",
    "    print(f\"  • Parametri totali: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"  • Parametri allenabili: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "    print(f\"  • Device: {next(model.parameters()).device}\")\n",
    "\n",
    "    # Informazioni sui dataloader\n",
    "    print(\"\\n[4] DATALOADER:\")\n",
    "    print(f\"  • Batch size training: {train_loader.batch_size}\")\n",
    "    print(f\"  • Batch size test: {test_loader.batch_size}\")\n",
    "    print(f\"  • Training batches: {len(train_loader)}\")\n",
    "    print(f\"  • Test batches: {len(test_loader)}\")\n",
    "    print(f\"  • Num workers: {train_loader.num_workers}\")\n",
    "\n",
    "    # Informazioni sul sistema\n",
    "    print(\"\\n[5] SISTEMA:\")\n",
    "    print(f\"  • PyTorch version: {torch.__version__}\")\n",
    "    print(f\"  • CUDA disponibile: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  • Dispositivo CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"  • Memoria totale GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        print(f\"  • Memoria allocata GPU: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "    print(f\"  • CPU count: {os.cpu_count()}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" \"*25 + \"CONFIGURAZIONE PRONTA PER L'ADDESTRAMENTO\" + \" \"*25)\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Chiamata alla funzione\n",
    "print_configuration_summary(dataset, train_loader, test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primo batch shape: torch.Size([128, 3, 81, 8, 8])\n",
      "Numero di classi: 7\n",
      "Classi: ['human structure', 'mudflat', 'street', 'vegetation 1', 'vegetation 2', 'vegetation 3', 'water']\n",
      "Iniziando training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/249 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensor must be of spatial size (32,32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 142\u001b[0m\n\u001b[1;32m    138\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, \u001b[38;5;241m90\u001b[39m):  \n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m    144\u001b[0m     train_accuracies\u001b[38;5;241m.\u001b[39mappend(train_acc)\n",
      "Cell \u001b[0;32mIn[16], line 49\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     46\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 49\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(output, target)\n\u001b[1;32m     51\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Projects/wavelet/wavelet_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/wavelet/wavelet_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Projects/wavelet/wavelet_lib/models.py:58\u001b[0m, in \u001b[0;36mTileWaveletClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 58\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscattering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mK, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures:\n",
      "File \u001b[0;32m~/Projects/wavelet/wavelet_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/wavelet/wavelet_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Projects/wavelet/wavelet_lib/base.py:43\u001b[0m, in \u001b[0;36mScatteringPreprocessor.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 43\u001b[0m     S \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscattering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     batch_size, channels, coeffs, h, w \u001b[38;5;241m=\u001b[39m S\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m S\u001b[38;5;241m.\u001b[39mview(batch_size, channels \u001b[38;5;241m*\u001b[39m coeffs, h, w)\n",
      "File \u001b[0;32m~/Projects/wavelet/wavelet_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/wavelet/wavelet_venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Projects/wavelet/wavelet_venv/lib/python3.12/site-packages/kymatio/frontend/torch_frontend.py:22\u001b[0m, in \u001b[0;36mScatteringTorch.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This method is an alias for `scattering`.\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minput_checks(x)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscattering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/wavelet/wavelet_venv/lib/python3.12/site-packages/kymatio/scattering2d/frontend/torch_frontend.py:83\u001b[0m, in \u001b[0;36mScatteringTorch2D.scattering\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor must be contiguous.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_pad:\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensor must be of spatial size (\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_N_padded \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_M_padded) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_pad:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPadded tensor must be of spatial size (\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_M_padded, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_N_padded))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensor must be of spatial size (32,32)."
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Directory per salvare i risultati\n",
    "save_dir = \"/home/brus/Projects/wavelet/elaborations/trained_models/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Ottimizzatore\n",
    "optimizer = SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.1,\n",
    "    momentum=0.9,\n",
    "    weight_decay=5e-4\n",
    ")\n",
    "\n",
    "# Funzione di valutazione\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            # Remove size check and interpolation\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            total += target.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Funzione di addestramento\n",
    "def train_epoch(model, loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(loader, desc=f'Epoch {epoch+1}')\n",
    "    for data, target in progress_bar:\n",
    "        # Sposta i dati sul device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Aggiorna statistiche\n",
    "        total_loss += loss.item() * target.size(0)\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += pred.eq(target).sum().item()\n",
    "        total += target.size(0)\n",
    "        \n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{correct/total:.4f}'\n",
    "        })\n",
    "    \n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "# Debug info\n",
    "first_batch, first_labels = next(iter(train_loader))\n",
    "print(f\"\\nPrimo batch shape: {first_batch.shape}\")\n",
    "print(f\"Numero di classi: {len(dataset.classes)}\")\n",
    "print(f\"Classi: {dataset.classes}\")\n",
    "# Funzione per plottare le metriche\n",
    "def plot_metrics(train_losses, train_accuracies, test_losses, test_accuracies, epoch, save=False):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot delle loss\n",
    "    ax1.plot(train_losses, label='Train Loss')\n",
    "    ax1.plot(test_losses, label='Test Loss')\n",
    "    ax1.set_title('Loss over epochs')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot delle accuracy\n",
    "    ax2.plot(train_accuracies, label='Train Accuracy')\n",
    "    ax2.plot(test_accuracies, label='Test Accuracy')\n",
    "    ax2.set_title('Accuracy over epochs')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'{save_dir}/metrics_epoch_{epoch+1}.png')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Funzione per caricare un checkpoint\n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    \"\"\"\n",
    "    Carica un checkpoint e restituisce il modello, l'ottimizzatore e le metriche\n",
    "    \"\"\"\n",
    "    print(f\"Caricamento checkpoint: {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    train_losses = checkpoint['train_losses']\n",
    "    train_accuracies = checkpoint['train_accuracies']\n",
    "    test_losses = checkpoint['test_losses']\n",
    "    test_accuracies = checkpoint['test_accuracies']\n",
    "    \n",
    "    print(f\"Checkpoint caricato dall'epoca {checkpoint['epoch']}\")\n",
    "    return model, optimizer, start_epoch, train_losses, train_accuracies, test_losses, test_accuracies\n",
    "\n",
    "\n",
    "# Metriche per il monitoraggio\n",
    "checkpoint_path = f\"{save_dir}/model_epoch_4000.pt\" \n",
    "if os.path.exists(checkpoint_path):\n",
    "    model, optimizer, start_epoch, train_losses, train_accuracies, test_losses, test_accuracies = load_checkpoint(\n",
    "        checkpoint_path, model, optimizer\n",
    "    )\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "\n",
    "# Training\n",
    "print(\"Iniziando training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(start_epoch, 90):  \n",
    "    # Training\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, epoch)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    \n",
    "    # Validation\n",
    "    test_loss, test_acc = evaluate(model, test_loader, device)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    # Stampa risultati\n",
    "    print(f'\\nEpoch {epoch+1}/90:')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    \n",
    "    # Plot ogni 10 epoche\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        plot_metrics(train_losses, train_accuracies, test_losses, test_accuracies, epoch)\n",
    "        \n",
    "        # Salva il checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_losses': train_losses,\n",
    "            'train_accuracies': train_accuracies,\n",
    "            'test_losses': test_losses,\n",
    "            'test_accuracies': test_accuracies,\n",
    "        }, f'{save_dir}/model_epoch_{epoch+1}.pt')\n",
    "\n",
    "# Tempo totale di training\n",
    "total_time = time.time() - start_time\n",
    "print(f'\\nTraining completato in {total_time/60:.2f} minuti')\n",
    "\n",
    "# Salva il modello finale\n",
    "torch.save({\n",
    "    'epoch': 90,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'train_accuracies': train_accuracies,\n",
    "    'test_losses': test_losses,\n",
    "    'test_accuracies': test_accuracies,\n",
    "}, f'{save_dir}/model_final.pt')\n",
    "\n",
    "# Plot finale\n",
    "plot_metrics(train_losses, train_accuracies, test_losses, test_accuracies, 89, save=True)\n",
    "print(f'Modello e grafici salvati in: {save_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione di inference\n",
    "def classify_tile(model, tile_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(tile_tensor)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        max_prob, label = torch.max(probabilities, dim=1)\n",
    "        return label.item(), max_prob.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wavelet_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
